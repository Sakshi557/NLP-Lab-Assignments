{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxac5icTJ+plMqK2Z06UkG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"8h0ztUi0ra4A","executionInfo":{"status":"ok","timestamp":1769017970370,"user_tz":-330,"elapsed":4,"user":{"displayName":"SAKSHI LOKHANDE","userId":"13056319053524434326"}}},"outputs":[],"source":["documents = [\n","    \"I love machine learning\",\n","    \"Machine learning is fun\",\n","    \"I love NLP\",\n","    \"NLP is a part of machine learning\"\n","]\n"]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Create CountVectorizer object\n","count_vectorizer = CountVectorizer()\n","\n","# Fit and transform the documents\n","bow_counts = count_vectorizer.fit_transform(documents)\n","\n","# Convert to array\n","bow_array = bow_counts.toarray()\n","\n","# Vocabulary\n","print(\"Vocabulary:\", count_vectorizer.get_feature_names_out())\n","\n","print(\"\\nBag of Words - Count Occurrence:\") #counts how many times a word occur in document\n","print(bow_array)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tA8IGjIEsAfd","executionInfo":{"status":"ok","timestamp":1769017993336,"user_tz":-330,"elapsed":4061,"user":{"displayName":"SAKSHI LOKHANDE","userId":"13056319053524434326"}},"outputId":"175ee099-525d-4c60-bf4f-e1f635d1fb21"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary: ['fun' 'is' 'learning' 'love' 'machine' 'nlp' 'of' 'part']\n","\n","Bag of Words - Count Occurrence:\n","[[0 0 1 1 1 0 0 0]\n"," [1 1 1 0 1 0 0 0]\n"," [0 0 0 1 0 1 0 0]\n"," [0 1 1 0 1 1 1 1]]\n"]}]},{"cell_type":"code","source":["from sklearn.preprocessing import normalize\n","\n","# Normalize word counts: Converts raw counts into relative frequencies\n","bow_normalized = normalize(bow_array, norm='l1')\n","\n","print(\"\\nBag of Words - Normalized Count:\")\n","print(bow_normalized)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njBDjAaOsqmR","executionInfo":{"status":"ok","timestamp":1769018162306,"user_tz":-330,"elapsed":53,"user":{"displayName":"SAKSHI LOKHANDE","userId":"13056319053524434326"}},"outputId":"2418f749-0755-485a-ced9-8a335d674636"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Bag of Words - Normalized Count:\n","[[0.         0.         0.33333333 0.33333333 0.33333333 0.\n","  0.         0.        ]\n"," [0.25       0.25       0.25       0.         0.25       0.\n","  0.         0.        ]\n"," [0.         0.         0.         0.5        0.         0.5\n","  0.         0.        ]\n"," [0.         0.16666667 0.16666667 0.         0.16666667 0.16666667\n","  0.16666667 0.16666667]]\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Create TF-IDF Vectorizer\n","tfidf_vectorizer = TfidfVectorizer()\n","\n","# Fit and transform\n","tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n","\n","print(\"\\nTF-IDF Vocabulary:\")\n","print(tfidf_vectorizer.get_feature_names_out())\n","\n","print(\"\\nTF-IDF Matrix:\")\n","print(tfidf_matrix.toarray())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-WIHNqosw7M","executionInfo":{"status":"ok","timestamp":1769018175316,"user_tz":-330,"elapsed":38,"user":{"displayName":"SAKSHI LOKHANDE","userId":"13056319053524434326"}},"outputId":"d03b8691-7ee6-4c55-8176-5473deae7ee4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","TF-IDF Vocabulary:\n","['fun' 'is' 'learning' 'love' 'machine' 'nlp' 'of' 'part']\n","\n","TF-IDF Matrix:\n","[[0.         0.         0.53256952 0.65782931 0.53256952 0.\n","  0.         0.        ]\n"," [0.64065543 0.5051001  0.40892206 0.         0.40892206 0.\n","  0.         0.        ]\n"," [0.         0.         0.         0.70710678 0.         0.70710678\n","  0.         0.        ]\n"," [0.         0.39137817 0.31685436 0.         0.31685436 0.39137817\n","  0.49641358 0.49641358]]\n"]}]},{"cell_type":"code","source":["!pip install gensim\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I8H6iIkMtAEm","executionInfo":{"status":"ok","timestamp":1769018240888,"user_tz":-330,"elapsed":8017,"user":{"displayName":"SAKSHI LOKHANDE","userId":"13056319053524434326"}},"outputId":"851b1365-0de4-4302-ffd5-7470ea9fb34f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n","Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gensim\n","Successfully installed gensim-4.4.0\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCbL5giJtVkV","executionInfo":{"status":"ok","timestamp":1769018321249,"user_tz":-330,"elapsed":471,"user":{"displayName":"SAKSHI LOKHANDE","userId":"13056319053524434326"}},"outputId":"53841c96-2c58-4f59-b455-a5446253f3d3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","from nltk.tokenize import word_tokenize\n","import nltk\n","\n","# Download tokenizer\n","nltk.download('punkt')\n","\n","# Tokenize sentences\n","tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n","\n","# Train Word2Vec model\n","word2vec_model = Word2Vec(\n","    sentences=tokenized_docs,\n","    vector_size=100,\n","    window=5,\n","    min_count=1,\n","    workers=4\n",")\n","\n","# Get vector for a word\n","print(\"\\nWord2Vec embedding for word 'machine':\")\n","print(word2vec_model.wv['machine'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPdzWh7Ms18O","executionInfo":{"status":"ok","timestamp":1769018323685,"user_tz":-330,"elapsed":179,"user":{"displayName":"SAKSHI LOKHANDE","userId":"13056319053524434326"}},"outputId":"b3c85b7d-e846-49c8-b48e-ac45e9f7ef90"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word2Vec embedding for word 'machine':\n","[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n","  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n"," -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n"," -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n","  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n","  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n","  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n"," -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n"," -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n","  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n","  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n"," -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n","  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n"," -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n","  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n"," -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n","  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n","  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n","  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n"," -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n"," -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n","  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n","  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n","  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n","  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]}]}